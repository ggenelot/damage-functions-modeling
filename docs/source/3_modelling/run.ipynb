{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing run.py\n",
      "Done every run\n"
     ]
    }
   ],
   "source": [
    "print('Executing run.py')\n",
    "\n",
    "# This script : \n",
    "# 1 - loads the VENSIM model into a python model with PySD,\n",
    "# 2 - launches a run to initialize the variables. Output variables are stored in a xarray dataset\n",
    "# 3 - Runs the model as many times as required, stores the output variable in the dataset with index 'Run'\n",
    "# 4 - Saves the dataset to a netCDF file that can be used for the later analysis\n",
    "\n",
    "import pysd\n",
    "import xarray as xr\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import utils.variables as vr\n",
    "\n",
    "if 0>1: \n",
    "\n",
    "    #############################################################\n",
    "    # Load the model and the variables\n",
    "    #############################################################\n",
    "\n",
    "    print('Loading model...')\n",
    "\n",
    "    # Suppress specific warnings to avoid cluttering the output\n",
    "    warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "    # Load model\n",
    "    model = pysd.read_vensim('WILIAM/WILIAM.mdl',\n",
    "                            split_views=True, \n",
    "                            subview_sep=[\".\"], \n",
    "                            errors='ignore')\n",
    "\n",
    "    print('Model loaded')\n",
    "\n",
    "    # Saving the variables \n",
    "    variables = model.doc\n",
    "\n",
    "    # Cleaning the variables and identifiying the model and equation \n",
    "    variables['Real Name'] = variables['Real Name'].str.replace('\"', '')\n",
    "    variables['Model'] = variables['Real Name'].str.split(':').str[0]\n",
    "    variables['Equation'] = variables['Real Name'].str.split(':').str[1]\n",
    "    variables['isEquation'] = variables['Real Name'].str.split(':').str[2].str.strip().str.startswith('EQ')\n",
    "    variables.loc[variables['Equation'].isnull(), 'Model'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "    #variables[\"Interest\"] = variables[\"Py Name\"].apply(lambda x: vr.isInterest(x))\n",
    "    #interest_variables = variables[variables[\"Interest\"] == True][\"Py Name\"].values\n",
    "    interest_variables = [\n",
    "        \"gini_gdppc_regions\", \n",
    "        \"gini_gdppc_eu27\", \n",
    "        \"temperature_change\", \n",
    "        \"temperature_change_in_35regions\", \n",
    "        \"total_population\", \n",
    "        \"population_35_regions\", \n",
    "        \"total_radiative_forcing\", \n",
    "        \"gross_domestic_product_nominal\", \n",
    "        \"average_disposable_income_per_capita\", \n",
    "        \"extra_extra_gdp_modifyer\"\n",
    "        ]\n",
    "\n",
    "    variables.to_csv('variables.csv')\n",
    "    variables_modelled = variables[variables['Model'].notna()]\n",
    "    variables_modelled_names = variables_modelled['Py Name'].values\n",
    "\n",
    "\n",
    "    # Adding other variables of interest\n",
    "\n",
    "\n",
    "\n",
    "    output_variables = np.concatenate([variables_modelled_names, interest_variables])\n",
    "\n",
    "\n",
    "    runs = pd.read_csv('run_manager.csv')\n",
    "\n",
    "\n",
    "\n",
    "    ## Preparing to vary the radiative forcing\n",
    "\n",
    "    # Load the basic radiative forcing \n",
    "    forcing = pd.read_csv('full_rcp.csv')\n",
    "\n",
    "    # Run the model a first time to initialize the dataset\n",
    "    output_ds_path = 'results/batch/run_ds_19_07_3.nc'\n",
    "\n",
    "    initial_time = 2005\n",
    "    final_time = 2010\n",
    "    time_step = 1 \n",
    "    time_span = time = np.linspace(initial_time, final_time, num=(final_time - initial_time)//time_step + 1)\n",
    "\n",
    "\n",
    "    exponent_values = np.random.normal(0, 1, len(time_span))\n",
    "    exponent = pd.Series(index=time_span, data=exponent_values)\n",
    "\n",
    "    norm_constant_values = np.random.uniform(10000, 50000, len(time_span))\n",
    "    norm_constant = pd.Series(index=time_span, data=norm_constant_values)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ############################################################################################################\n",
    "    # Initial run\n",
    "    ############################################################################################################\n",
    "\n",
    "\n",
    "    print(f\"Initializing the model for the first run\")\n",
    "\n",
    "\n",
    "    # Run the model\n",
    "    run = model.run(progress=True,\n",
    "                    params={'\"EXTRA: EXTRA: exponent\"' : exponent,\n",
    "                            '\"EXTRA: EXTRA: normalisation constant\"': norm_constant\n",
    "                            }, \n",
    "                    output_file=output_ds_path,\n",
    "                    return_columns=output_variables,\n",
    "                    final_time=final_time)\n",
    "\n",
    "\n",
    "    ## Preparing the dataset \n",
    "\n",
    "    ds = xr.open_dataset(output_ds_path)\n",
    "\n",
    "    run_num =  10 #len(runs)\n",
    "    ds = ds.expand_dims({\"Run\": run_num}).assign_coords({\"Run\": range(0, run_num)})\n",
    "    ds = ds.rename({'REGIONS 35 I': 'region'})\n",
    "\n",
    "\n",
    "    runs = runs.head(run_num)\n",
    "\n",
    "\n",
    "\n",
    "    ############################################################################################################\n",
    "    # Other runs\n",
    "    ############################################################################################################\n",
    "\n",
    "    # Iterate over the rows of the run manager\n",
    "    for index, run in runs.iterrows():\n",
    "        \n",
    "        first_run = True\n",
    "\n",
    "        print(\"Initializing forcing... \")\n",
    "        rcp = run['RCP']\n",
    "        forcing_columns = [rcp,  'time']\n",
    "        total_forcing = forcing[forcing_columns]\n",
    "        total_forcing = pd.Series(index=total_forcing['time'], data=total_forcing[rcp].values)\n",
    "        print(\"Forcing initialized\")\n",
    "        \n",
    "        exponent_values = np.random.normal(0, 1, len(time_span))\n",
    "        exponent = pd.Series(index=time_span, data=exponent_values)\n",
    "\n",
    "        norm_constant_values = np.random.uniform(10000, 50000, len(time_span))\n",
    "        norm_constant = pd.Series(index=time_span, data=norm_constant_values)\n",
    "\n",
    "        print(f\"Running model for run {run['run_number']}\")\n",
    "\n",
    "\n",
    "        # Run the model\n",
    "        run = model.run(progress=True,\n",
    "                        params={'total radiative forcing': total_forcing, \n",
    "                                '\"EXTRA: EXTRA: exponent\"' : exponent,\n",
    "                                '\"EXTRA: EXTRA: normalisation constant\"': norm_constant\n",
    "                                },\n",
    "                        return_columns=output_variables,\n",
    "                        final_time=final_time)\n",
    "        \n",
    "        # Store the simulation results in a dataframe\n",
    "\n",
    "        result_variables = run.columns \n",
    "\n",
    "        \n",
    "\n",
    "        extra_extra_exponent_copy = ds[\"extra_extra_exponent\"].copy()\n",
    "        extra_extra_exponent_copy.loc[dict(Run = index)] = exponent\n",
    "        ds[\"extra_extra_exponent\"] = extra_extra_exponent_copy\n",
    "\n",
    "        extra_extra_normalisation_constant_copy = ds[\"extra_extra_normalisation_constant\"].copy()\n",
    "        extra_extra_normalisation_constant_copy.loc[dict(Run = index)] = norm_constant\n",
    "        ds[\"extra_extra_normalisation_constant\"] = extra_extra_normalisation_constant_copy\n",
    "\n",
    "\n",
    "        run = run.reset_index()\n",
    "        \n",
    "        for i in range(0, len(run.columns)):\n",
    "\n",
    "            try: \n",
    "                    column_name = run.columns.to_list()[i].strip()\n",
    "                    #print(column_name)\n",
    "                    variable_name = column_name.split('[')[0].strip()\n",
    "                    region = column_name.split('[')[1].split(']')[0].strip()\n",
    "                    #print(f'Variable : {variable_name}, region {region}')\n",
    "                    variable_copy = ds[variable_name].copy()\n",
    "                    #print('Before adding')\n",
    "                    #print(run[column_name].values)\n",
    "                    variable_copy.loc[dict(Run = index,  region=region)] = run[column_name].values\n",
    "                    #print('After copying')\n",
    "                    ds[variable_name] = variable_copy\n",
    "                    #print(f\"Added variable {variable_name} in region {region} to the dataset.\")\n",
    "                    \n",
    "            except:      \n",
    "                    try: \n",
    "                            variable_name = run.columns.to_list()[i].strip()\n",
    "                            variable_copy = ds[variable_name].copy()\n",
    "                            variable_copy.loc[dict(Run = index)] = run[variable_name].values\n",
    "                            ds[variable_name] = variable_copy\n",
    "                            print(f\"NO REGION - Added variable {variable_name} to the dataset.\")\n",
    "                    except:\n",
    "                            print(f'FAILED to add variable {run.columns.to_list()[i]}')\n",
    "\n",
    "    ds.to_netcdf(output_ds_path)\n",
    "    ds.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    warnings.resetwarnings()\n",
    "\n",
    "print('Done every run')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
